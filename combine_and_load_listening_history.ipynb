{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a209ed-e61d-48bd-ab06-f7c777c2331a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 15:26:36,632 - INFO - ======== Start of Run: 2024-09-25 15:26:36.632226 =======\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is the highest numbered json file? 6\n",
      "There is an existing full history file present. Overwrite? (yes/no): no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 15:26:40,158 - INFO - Operation cancelled.\n",
      "2024-09-25 15:26:40,160 - INFO - ======== End of Run: 2024-09-25 15:26:40.160796 =======\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script to process and consolidate music listening history data from JSON files provided by Spotify.\n",
    "\n",
    "Files will need to be named endsong_X.json, where X is the number. Spotify changes file naming conventions periodically, so this is not automated.\n",
    "\n",
    "This script performs the following steps:\n",
    "1. Initialize logging and load configuration settings.\n",
    "2. Check for existing consolidated files and handle user input for overwriting.\n",
    "3. Iterate through JSON files of music listening history to load and clean data.\n",
    "4. Save cleaned data to CSV and combine them into a master CSV file.\n",
    "5. Load the consolidated data into the database.\n",
    "\"\"\"\n",
    "\n",
    "from utils.logging_config import setup_logger, finalize_logger\n",
    "from utils.file_utils import (\n",
    "    load_config,\n",
    "    get_current_date_string,\n",
    "    get_file_count,\n",
    "    load_json_to_dataframe,\n",
    "    clean_dataframe,\n",
    "    save_dataframe_to_csv,\n",
    "    combine_csv_files,\n",
    "    load_and_clean_csv,\n",
    ")\n",
    "from utils.db_utils import initialize_db, load_data_to_db, music_listening_history_table\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to process, consolidate, and load music listening history.\"\"\"\n",
    "    logger = setup_logger('combine_load_data_logger', 'combine_load_data.log', log_level='INFO')\n",
    "    config = load_config()\n",
    "\n",
    "    # Retrieves the current date as a string and get the number of JSON files to process\n",
    "    date_string = get_current_date_string()\n",
    "    file_count = get_file_count()\n",
    "\n",
    "    # Defines the path for the master CSV file based on the data path from the config\n",
    "    data_path = config[\"Paths\"][\"data_path\"]\n",
    "    master_file_path = os.path.join(data_path, f\"Spotify_Listening_Data.csv\")\n",
    "\n",
    "    # Checks if the master file already exists, prompting user to delete if so\n",
    "    if os.path.isfile(master_file_path):\n",
    "        user_input = input(\n",
    "            \"There is an existing full history file present. Overwrite? (yes/no):\"\n",
    "        )\n",
    "        if user_input.strip().lower() == \"yes\":\n",
    "            os.remove(master_file_path)\n",
    "            logger.info(\"Existing file removed.\")\n",
    "        else:\n",
    "            logger.info(\"Operation cancelled.\")\n",
    "            finalize_logger(logger)\n",
    "            return\n",
    "    # Iterates through the range of JSON files to process\n",
    "    for loop_number in range(file_count + 1):\n",
    "        # Constructs the file path for the current JSON file\n",
    "        input_file_path = os.path.join(data_path, f\"endsong_{loop_number}.json\")\n",
    "        logger.info(f\"Processing file: {input_file_path}\")\n",
    "\n",
    "        # Loads the JSON data into a DataFrame, drops and renames fields\n",
    "        df = load_json_to_dataframe(input_file_path)\n",
    "        df = clean_dataframe(df)\n",
    "\n",
    "        # If processing the first file, saves it as the master file\n",
    "        if loop_number == 0:\n",
    "            save_dataframe_to_csv(df, master_file_path)\n",
    "        else:\n",
    "            # For subsequent files, saves to a temporary CSV file and combines\n",
    "            current_file_path = os.path.join(\n",
    "                data_path, f\"Spotify_Listening_Data_{date_string}_{loop_number}.csv\"\n",
    "            )\n",
    "            save_dataframe_to_csv(df, current_file_path)\n",
    "            combine_csv_files(master_file_path, current_file_path)\n",
    "            # Removes the temporary file after combining\n",
    "            os.remove(current_file_path)\n",
    "\n",
    "    logger.info(\"Data consolidation complete.\")\n",
    "\n",
    "    db, metadata = initialize_db()\n",
    "\n",
    "    csv_df = load_and_clean_csv(master_file_path)\n",
    "    load_data_to_db(csv_df, db, music_listening_history_table.name, logger)\n",
    "\n",
    "    finalize_logger(logger)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
