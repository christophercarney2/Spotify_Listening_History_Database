{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79eb3f62-6186-4535-a602-811bb60f6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to process track data from a CSV file, interact with the Spotify API to fetch detailed information about tracks, albums, and artists, \n",
    "and insert or update this data into a SQL database. \n",
    "\n",
    "This script performs the following steps:\n",
    "1. Initialize logging and the Spotify API client, connect to the database.\n",
    "2. Read and process the master CSV file containing listening history data.\n",
    "3. Fetch new tracks and their corresponding audio features, albums, and artists from Spotify.\n",
    "4. Insert new records into the relevant database tables while checking for duplicates.\n",
    "\n",
    "This script is designed to handle batch processing of tracks to efficiently manage API calls and database operations.\n",
    "It may fail due to the unpredictability of Spotify's rate limiting, but will eventually be able to be restarted.\n",
    "\"\"\"\n",
    "\n",
    "from utils.logging_config import setup_logger, finalize_logger\n",
    "from utils.file_utils import read_and_process_track_csv, get_batch_track_uris\n",
    "from utils.spotify_utils import MaxRetriesExceededException, get_spotify_client, fetch_batch_tracks, fetch_audio_features, fetch_album, fetch_artist\n",
    "from utils.db_utils import initialize_db, check_new_tracks_and_artists, insert_track_artist, insert_new_track, insert_album, insert_artist, update_audio_features, music_listening_history_table, tracks_table, track_artists_table, artists_table, artist_genre_table, albums_table, track_mapping_table, tracks_consolidated_table\n",
    "from sqlalchemy import select, and_\n",
    "from datetime import datetime\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a66266c-43ea-42c8-bcb8-88f94d550359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(sp, conn, start_index, batch_track_uris, tracks_table, track_artists_table, artists_table, artist_genre_table, albums_table, logger):\n",
    "    \"\"\"\n",
    "    Process a batch of track URIs, checking for new tracks and their respective artists and albums.\n",
    "    Insert data into respective tables if not already present.\n",
    "\n",
    "    Args:\n",
    "        sp (spotipy.Spotify): Spotify client instance.\n",
    "        conn (Connection): SQLAlchemy connection object.\n",
    "        start_index (int): The track number in the file to start processing at.\n",
    "        batch_track_uris (list): List of track URIs to be processed.\n",
    "        tracks_table (Table): SQLAlchemy Table object for the tracks table.\n",
    "        track_artists_table (Table): SQLAlchemy Table object for the track_artists table.\n",
    "        artists_table (Table): SQLAlchemy Table object for the artists table.\n",
    "        artist_genre_table (Table): SQLAlchemy Table object for the artist_genre table.\n",
    "        albums_table (Table): SQLAlchemy Table object for the albums table.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Checks if there are new tracks or new track artists in the current batch\n",
    "    batch_has_new_tracks, batch_has_new_track_artists = check_new_tracks_and_artists(conn, batch_track_uris, tracks_table, track_artists_table)\n",
    "    \n",
    "    if batch_has_new_tracks or batch_has_new_track_artists:\n",
    "        logger.info(f\"New tracks or track artists found in batch starting at index {start_index}.\")\n",
    "        # Fetches detailed track information from Spotify API for the batch\n",
    "        batch_tracks = fetch_batch_tracks(logger, sp, batch_track_uris)\n",
    "\n",
    "        if batch_has_new_track_artists:\n",
    "            # Inserts new track-artist associations to the database\n",
    "            handle_new_track_artists(conn, batch_tracks, track_artists_table, logger)\n",
    "\n",
    "        if batch_has_new_tracks:\n",
    "            # Fetches audio features from the Spotify API for new tracks in the batch\n",
    "            af_batch_tracks = fetch_audio_features(logger, sp, batch_track_uris)\n",
    "            # Inserts new tracks to the database\n",
    "            handle_new_tracks(sp, conn, batch_tracks, af_batch_tracks, tracks_table, albums_table, artists_table, artist_genre_table, logger)\n",
    "    else:\n",
    "        logger.info(f\"No new tracks or track artists found in batch starting at index {start_index}.\")\n",
    "\n",
    "def handle_new_track_artists(conn, batch_tracks, track_artists_table, logger):\n",
    "    \"\"\"\n",
    "    Handle the insertion of new track-artist associations for tracks in a batch.\n",
    "\n",
    "    Args:\n",
    "        conn (Connection): SQLAlchemy connection object.\n",
    "        batch_tracks (dict): Dictionary containing track details from Spotify.\n",
    "        track_artists_table (Table): SQLAlchemy table object for the 'track_artists' table.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterates over each track in the batch\n",
    "    for track in batch_tracks['tracks']:\n",
    "        spotify_track_uri = track['uri']\n",
    "        spotify_track_id = track['id']\n",
    "        track_name = track['name']\n",
    "        track_artists = track['artists']\n",
    "\n",
    "        # Inserts each new track-artist association into the database\n",
    "        for track_artist in track_artists:\n",
    "            insert_track_artist(conn, track_artists_table, spotify_track_uri, spotify_track_id, track_artist, logger)\n",
    "    conn.commit() \n",
    "    logger.info('Track artists committed')\n",
    "\n",
    "def handle_new_tracks(sp, conn, batch_tracks, af_batch_tracks, tracks_table, albums_table, artists_table, artist_genre_table, logger):\n",
    "    \"\"\"\n",
    "    Process new tracks and their audio features, albums, and artists. Insert them into the database.\n",
    "\n",
    "    Args:\n",
    "        sp (spotipy.Spotify): Spotify client instance.\n",
    "        conn (Connection): SQLAlchemy connection object.\n",
    "        batch_tracks (dict): Dictionary containing track details from Spotify.\n",
    "        af_batch_tracks (list): List of audio features for the tracks.\n",
    "        tracks_table (Table): SQLAlchemy table object for the 'tracks' table.\n",
    "        albums_table (Table): SQLAlchemy table object for the 'albums' table.\n",
    "        artists_table (Table): SQLAlchemy table object for the 'artists' table.\n",
    "        artist_genre_table (Table): SQLAlchemy table object for the 'artist_genre' table.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Loops over each track and its audio features\n",
    "        for track, audio_features in zip(batch_tracks['tracks'], af_batch_tracks):\n",
    "            if track is None:\n",
    "                logger.warning(\"Skipping track due to missing data\")\n",
    "                continue\n",
    "\n",
    "            # Checks if the track is already in the tracks table\n",
    "            if not conn.execute(select(tracks_table).where(tracks_table.c.spotify_track_uri == track['uri'])).scalar():\n",
    "                insert_new_track(conn, tracks_table, track, logger)\n",
    "\n",
    "            # Logs if audio features are missing, otherwise inserts/updates them\n",
    "            if audio_features is None:\n",
    "                logger.warning(f\"Skipping audio feature due to missing data for track: {track.get('id')} {track.get('name', 'Unknown')}\")\n",
    "            else:\n",
    "                update_audio_features(conn, tracks_table, audio_features)\n",
    "                logger.info(f\"Updated audio features for {track.get('id')} {track.get('name')}\")\n",
    "\n",
    "            # Inserts each new album and artist into the database\n",
    "            handle_album(sp, conn, track['album'], albums_table, logger)\n",
    "            handle_artists(sp, conn, track['artists'], artists_table, artist_genre_table, logger)\n",
    "\n",
    "        # Commits the transaction only after all operations are complete\n",
    "        conn.commit() \n",
    "        logger.info('Tracks, albums, artists, and audio features committed')\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Transaction failed for batch starting at index {start_index}. Error: {e}\")\n",
    "        raise\n",
    "\n",
    "def handle_album(sp, conn, album, albums_table, logger):\n",
    "    \"\"\"\n",
    "    Handle the insertion of a new album into the 'albums' table.\n",
    "\n",
    "    Args:\n",
    "        sp (spotipy.Spotify): Spotify client instance.\n",
    "        conn (Connection): SQLAlchemy connection object.\n",
    "        album (dict): Dictionary containing album details from Spotify.\n",
    "        albums_table (Table): SQLAlchemy table object for the 'albums' table.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Checks if the album is already in the albums table\n",
    "    if not conn.execute(select(albums_table).where(and_(albums_table.c.spotify_artist_id == album['artists'][0]['id'], albums_table.c.spotify_album_id == album['id']))).scalar():\n",
    "        insert_album(conn, albums_table, fetch_album(logger, sp, album['uri']), logger)\n",
    "\n",
    "def handle_artists(sp, conn, track_artists, artists_table, artist_genre_table, logger):\n",
    "    \"\"\"\n",
    "    Handle the insertion of new artists into the artists and artist_genre tables.\n",
    "\n",
    "    Args:\n",
    "        sp (spotipy.Spotify): Spotify client instance.\n",
    "        conn (Connection): SQLAlchemy connection object.\n",
    "        track_artists (list): List of artists associated with a track.\n",
    "        artists_table (Table): SQLAlchemy table object for the 'artists' table.\n",
    "        artist_genre_table (Table): SQLAlchemy table object for the 'artist_genre' table.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    for track_artist in track_artists:\n",
    "        # Checks if the artist is already in the artists table\n",
    "        if not conn.execute(select(artists_table).where(artists_table.c.spotify_artist_id == track_artist['id'])).scalar():\n",
    "            insert_artist(conn, artists_table, artist_genre_table, fetch_artist(logger, sp, track_artist['uri']), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf4a8c-bbe7-405a-ba78-95d3488f60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to handle the batch processing of tracks from CSV data, make relevant Spotify\n",
    "    API calls and insert the returned data into the appropriate database tables\n",
    "    \"\"\"\n",
    "\n",
    "    logger = setup_logger('spotify_api_batch_logger', 'spotify_api_batch.log', log_level='INFO')\n",
    "    db, metadata = initialize_db()\n",
    "    sp = get_spotify_client()\n",
    "    track_df = read_and_process_track_csv()\n",
    "    \n",
    "    # Constants for batch processing\n",
    "    start_index = int(input(\"Enter the starting index. If this is the first run, enter 0: \"))\n",
    "    batch_size = 50\n",
    "    \n",
    "    try:\n",
    "        # Processes batches of tracks until all are handled\n",
    "        while start_index < len(track_df):\n",
    "            # Retrieves a batch of track URIs from the DataFrame\n",
    "            batch_track_uris = get_batch_track_uris(track_df, start_index, batch_size)\n",
    "\n",
    "            with db.connect() as conn:\n",
    "                # Makes Spotify API calls on batch tracks, insert new data into database\n",
    "                process_batch(sp, conn, start_index, batch_track_uris, tracks_table, track_artists_table, artists_table, artist_genre_table, albums_table, logger)\n",
    "\n",
    "                start_index += batch_size\n",
    "\n",
    "    except MaxRetriesExceededException as e:\n",
    "        # This will stop the script completely on max retries.\n",
    "        logger.error(f\"Max retries exceeded: {e}\")\n",
    "        raise\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred. Batch start index is {start_index}: {e}\") \n",
    "\n",
    "    finally:\n",
    "        # Ensure the logger is properly closed regardless of outcome\n",
    "        finalize_logger(logger)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67c9e3-bb81-4df7-864c-512c41a7e38f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
